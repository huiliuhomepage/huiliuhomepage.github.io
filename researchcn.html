<html lang="cn">
	<head>
		<meta charset="utf-8">
		<title>刘辉的学术经历（0000-0002-6850-9570）</title>
		<style>
			html, body, form, fieldset, p, div, h1, h2, h3, h4, h5, h6 {-webkit-text-size-adjust:100%;}
			body {font: normal 16px Verdana, Arial, sans-serif;}
			img {transition: transform .5s;}
			img:hover {transform: scale(2.5);}
			.pop1:hover {transform: scale(1.6);}
			.pop5:hover {transform: scale(5);}
			.pop15:hover {transform: scale(15);}
			.pop20:hover {transform: scale(20);}
			.pop25:hover {transform: scale(25);}
			.pop40:hover {transform: scale(40);}
		</style>
	</head>

	<body background="images/Arrowhead.svg" link="#000000" alink="#0080FF" vlink = "#000000">
		<div class="main" id="home">
			<br>
			<h3 align="left"><font face="sans" size="5">
				&nbsp;&nbsp;<a href="indexcn.html">首 页</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a>学 术</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="artcn.html">艺 术</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="academictreecn.html">学术族谱</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="arttreecn.html">艺术族谱</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="research.html"><img src="images/EN.svg" height="15"></a>
			</font></h3>
		</div>
		
		<br><br><br><br><br>
		
		<table align="left" cellpadding="15">
			<tr><td><h1 align="left"><span style="text-decoration: overline">学术链接</span></h1></td></tr>
			<tr><td><table align="left" cellpadding="15">
				<tr>
					<td>
						<a href="https://www.uni-bremen.de/en/csl/institute/team/staff/dr-hui-liu" target="_blank" rel="noopener noreferrer"><img src="images/EN.svg" height="20" class="pop2"></a>&nbsp;&nbsp;&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl/institut/team/mitarbeiter/dr-hui-liu" target="_blank" rel="noopener noreferrer"><img src="images/DE.svg" height="20" class="pop2"></a>
					</td>
					<td><b>个人学术主页@不来梅大学</b></td>
				</tr>
				<tr><td><a href="https://orcid.org/0000-0002-6850-9570" target="_blank" rel="noopener noreferrer"><img src="images/ORCID.png" height="20" class="pop2"></a></td><td>0000-0002-6850-9570</td></tr>
				<tr><td><a href="https://scholar.google.com/citations?user=GyLOsRwAAAAJ" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="20" class="pop2"></a></td><td>GyLOsRwAAAAJ</td></tr>
				<tr><td><a href="https://www.researchgate.net/profile/Hui-Liu-149" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="20" class="pop2"></a></td><td>Hui-Liu-149</td></tr>
				<tr><td><a href="https://www.scopus.com/authid/detail.uri?authorId=57196004640" target="_blank" rel="noopener noreferrer"><img src="images/Scopus.png" height="20" class="pop2"></a><td>57196004640</td></td></tr>
				<tr><td><a href="https://www.semanticscholar.org/author/Hui-Liu/2146672447" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="20" class="pop2"></a></td><td>2146672447</td></tr>
				<tr><td><a href="https://www.webofscience.com/wos/author/record/ACZ-9903-2022" target="_blank" rel="noopener noreferrer"><img src="images/WoS.png" height="20" class="pop2"></a></td><td>ACZ-9903-2022</td></tr>
				<tr><td></td></tr>
				<tr>
					<td>
						欢迎您将最新学术成果投稿：<br>
						《面向人体动作的传感器研究 卷II》</b>
					</td>
					<td>
						<a href="https://www.mdpi.com/journal/sensors/special_issues/671TM05M9J" target="_blank" rel="noopener noreferrer"><img src="images/Sensors.png" height="40"></a>
						&nbsp;&nbsp; <a href="https://www.mdpi.com/journal/sensors/special_issue_flyer_pdf/Sensors_Human_Activity_Recognition/web"><img src="images/Download.png" height="15"></a>
					</td>
				</tr>
			</table></td></tr>

			<tr><td></td></tr><tr><td></td></tr>

			<tr><td><h1 align="left"><span style="text-decoration: overline">研究领域</span></h1></td></tr>
			<tr><td><table align="left" cellpadding="15">
				<tr><td>
					生医工 BME、普适计算 UbiComp、人体动作识别 HAR HBR、表情识别 AUR、肌肉协同、<br><br>
					体域网 (W)BAN (W)BSN、可穿戴 Wearables、惯性传感器 IMU、肌电 (s/f)EMG、测角仪 EGM、<br><br>
					人工智能 AI、机器学习 ML、隐马尔可夫 HMM、大数据挖掘 BDM、信息检索 IR、离群点检测 OD、<br><br>
					开源时序信号分析代码库：<a href="https://tsfel.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">特征提取</a> 和 <a href="https://tssearch.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">子序列搜索</a>、自相似 SSM、时序信号自动分割标定、<br><br>
					开源可穿戴式多模态人体动作数据集：<a href="https://www.uni-bremen.de/en/csl/research/human-activity-recognition" target="_blank" rel="noopener noreferrer">CSL-SHARE</a>、人体动作建模：MU (motion units)、<br><br>
					人机交互 HCI CHI、实时系统 RTS、元宇宙 Metaverse、虚拟/增加/混合现实 VR AR MR XR、<br><br>
					音乐信息检索 MIR、传统音乐 folk music、演唱辅助 singing assistance 等。
				</td></tr>

				<tr><td colspan="2">
					<video width="560" controls="controls">
						<source src="https://seafile.zfn.uni-bremen.de/f/6c96c91c878d4d1caa66/?dl=1" type="video/mp4" />
					</video>
					 （<a href="https://www.youtube.com/embed/MseG4XWuGzs" target="_blank" rel="noopener noreferrer"><img src="images/YouTube.png" height="13"></a>）<br><br>
					研发出第一款可实时识别人体动作、提供医疗康复辅助的智能膝盖绷带<br>
					获第12届国际生物医学工程系统和技术联合会议 <a href="https://biostec.scitevents.org/PreviousAwards.aspx#2019" target="_blank" rel="noopener noreferrer"><img src="images/BIOSTEC2019.png" width="80"></a> <a href="https://biostec.scitevents.org/PreviousAwards.aspx#2019" target="_blank" rel="noopener noreferrer">最佳论文奖</a>（学生作者）	
					<img src="images/BestPaperAward.png" height="25" class="pop25"> <img src="images/BestPaper.png" height="15" class="pop25">
				</td></tr>
			</table></td></tr>

			<tr><td></td></tr><tr><td></td></tr>
		
			<tr><td><h1 align="left"><span style="text-decoration: overline">论文发表</span></h1></td></tr>
			<tr><td><table align="left" cellpadding="15">
				<tr><td>
					<img src="images/Book.png" height="25">&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/Dissertation.png" height="25">
				</tr></td>
				<tr><td>
					<i>Sensors for Human Activity Recognition.</i> Liu, H., Gamboa, H., and Schultz, T. (2023). MDPI.<br>
					<a href="https://www.google.de/books/edition/Sensors_for_Human_Activity_Recognition/jTID0AEACAAJ" target="_blank" rel="noopener noreferrer"><img src="images/GoogleBooks.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.amazon.com/Sensors-Human-Activity-Recognition-Hui/dp/3036575545" target="_blank" rel="noopener noreferrer"><img src="images/Amazon.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/372077993_Sensors_for_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2023sensors_har&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/books/book/7447" target="_blank" rel="noopener noreferrer"><img src="images/MDPIBooks.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3390/books978-3-0365-7555-1" target="_blank" rel="noopener noreferrer">10.3390/books978-3-0365-7555-1</a>
				</tr></td>
				<tr><td>
					<i>Biosignal processing and activity modeling for multimodal human activity recognition.</i> Liu, H. (2021). PhD thesis, University of Bremen.<br>
					<a href="https://scholar.google.com/scholar?q=Biosignal+Processing+and+Activity+Modeling+for+Multimodal+Human+Activity+Recognition" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/356683096_Biosignal_Processing_and_Activity_Modeling_for_Multimodal_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://theses.eurasip.org/theses/911/biosignal-processing-and-activity-modeling-for/" target="_blank" rel="noopener noreferrer"><img src="images/Eurasip.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://media.suub.uni-bremen.de/handle/elib/5492" target="_blank" rel="noopener noreferrer"><img src="images/SuUB.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2021thesis&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.26092/elib/1219" target="_blank" rel="noopener noreferrer">10.26092/elib/1219</a>
				</tr></td>
			
				<tr><td>
					<img src="images/Chapter.png" height="25">
				</tr></td>
				<tr><td>
					<i>High-Level Features for Human Activity Recognition and Modeling.</i> Hartmann, Y., Liu, H., and Schultz, T. (2023). Biomedical Engineering Systems and Technologies. Springer Nature Switzerland.<br>
					<a href="https://scholar.google.com/scholar?q=High-Level+Features+for+Human+Activity+Recognition+and+Modeling" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/High-Level-Features-for-Human-Activity-Recognition-Hartmann-Liu/d247cc3dbe4ea9673b8f2bebdd62a10eef42d978" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/372525464_High-Level_Features_for_Human_Activity_Recognition_and_Modeling" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.springerprofessional.de/high-level-features-for-human-activity-recognition-and-modeling/25835520" target="_blank" rel="noopener noreferrer"><img src="images/Springer_Professional.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/chapter/10.1007/978-3-031-38854-5_8" target="_blank" rel="noopener noreferrer"><img src="images/SpringerLink.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=hartmann2023hlf&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1007/978-3-031-38854-5_8" target="_blank" rel="noopener noreferrer">10.1007/978-3-031-38854-5_8</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/book/10.1007/978-3-642-18472-7" target="_blank" rel="noopener noreferrer"><img src="images/Book.png" height="15" class="pop15"></a>
				</tr></td>
				<tr><td>
					<i>Sensor-Based Human Activity and Behavior Research: Where Advanced Sensing and Recognition Technologies Meet.</i> Liu, H.*, Gamboa, H., and Schultz, T. (2023). Sensors, 23(1):125. MDPI.<br>
					<a href="https://scholar.google.com/scholar?q=sensor-based+human+activity+and+behavior+research" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Sensor-Based-Human-Activity-and-Behavior-Research%3A-Liu-Gamboa/d775d7f0105130e9f47ef95fd73d46243e385848" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/366563962_Sensor-Based_Human_Activity_and_Behavior_Research_Where_Advanced_Sensing_and_Recognition_Technologies_Meet" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/1424-8220/23/1/125" target="_blank" rel="noopener noreferrer"><img src="images/Sensors.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2023sensorseditorial&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3390/s23010125" target="_blank" rel="noopener noreferrer">10.3390/s23010125</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/books/book/7447" target="_blank" rel="noopener noreferrer"><img src="images/Book.png" height="15" class="pop15"></a>
				</tr></td>
				<tr><td>
					<i>Hidden Markov Model and Its Application in Human Activity Recognition and Fall Detection: A Review.</i> Xue, T., and Liu, H. (2022). Communications, Signal Processing, and Systems. Springer, Singapore.<br>
					<a href="https://scholar.google.com/scholar?q=Hidden+Markov+Model+and+Its+Application+in+Human+Activity+Recognition+and+Fall+Detection%3A+A+Review" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Hidden-Markov-Model-and-Its-Application-in-Human-A-Xue-Liu/b37df2bc1532b776845dd48e4fa034c47a3dc39c" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/355198894_Hidden_Markov_Model_and_Its_Application_in_Human_Activity_Recognition_and_Fall_Detection_A_Review" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.springerprofessional.de/hidden-markov-model-and-its-application-in-human-activity-recogn/20265550" target="_blank" rel="noopener noreferrer"><img src="images/Springer_Professional.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/chapter/10.1007/978-981-19-0390-8_108" target="_blank" rel="noopener noreferrer"><img src="images/SpringerLink.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=xue2021hmm&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1007/978-981-19-0390-8_108" target="_blank" rel="noopener noreferrer">10.1007/978-981-19-0390-8_108</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/book/10.1007/978-981-19-0390-8" target="_blank" rel="noopener noreferrer"><img src="images/Book.png" height="15" class="pop15"></a>
				</tr></td>
				<tr><td>
					<i>Bremen Big Data Challenge 2017: Predicting University Cafeteria Load.</i> Weiner, J., Diener, L., Stelter, S., Externest, E., Kühl, S., Herff, C., Putze, F., Schulze, T., Salous, M., Liu, H., Küster, D., and Schultz, T. (2017). KI 2017: Advances in Artificial Intelligence. Springer, Cham.<br>
					<a href="https://scholar.google.com/scholar?q=Bremen+Big+Data+Challenge+2017%3A+Predicting+University+Cafeteria+Load" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Bremen-Big-Data-Challenge-2017%3A-Predicting-Load-Weiner-Diener/8ba8727f1e80e598619788888ace58effcaa51de" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/319890452_Bremen_Big_Data_Challenge_2017_Predicting_University_Cafeteria_Load" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.springerprofessional.de/bremen-big-data-challenge-2017-predicting-university-cafeteria-l/15121170" target="_blank" rel="noopener noreferrer"><img src="images/Springer_Professional.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/chapter/10.1007/978-3-319-67190-1_35" target="_blank" rel="noopener noreferrer"><img src="images/SpringerLink.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=Weiner2017&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://bbdc.csl.uni-bremen.de/index.php/2017" target="_blank" rel="noopener noreferrer"><img src="images/BBDC2017.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1007/978-3-319-67190-1_35" target="_blank" rel="noopener noreferrer">10.1007/978-3-319-67190-1_35</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://link.springer.com/book/10.1007/978-3-319-67190-1" target="_blank" rel="noopener noreferrer"><img src="images/Book.png" height="15" class="pop15"></a>
				</tr></td>
			
				<tr><td>
					<img src="images/Journal.png" height="25">
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Robust Human Locomotion and Localization Activity Recognition over Multisensory.</i> Khan, D., Alonazi, M., Abdelhaq, M.*, Mudawi, N. A., Algarni, A., Jalal, A.*, Liu, H.* (2024).  In Frontiers in Physiology.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<i>MS2OD: Outlier Detection Using Minimum Spanning Tree and Medoid Selection.</i> Li, J., Li, JW, Wang, C., Verbeek F. J.*, Schultz, T., and Liu, H.* (2024). Machine Learning: Science and Technology. IOPscience.<br>
					<a href="https://scholar.google.com/scholar?q=MS2OD%3A+Outlier+Detection+Using+Minimum+Spanning+Tree+and+Medoid+Selection" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/377861624_MS2OD_Outlier_Detection_Using_Minimum_Spanning_Tree_and_Medoid_Selection" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://iopscience.iop.org/article/10.1088/2632-2153/ad2492" target="_blank" rel="noopener noreferrer"><img src="images/IOP.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=li2024ms2od&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1088/2632-2153/ad2492" target="_blank" rel="noopener noreferrer">10.1088/2632-2153/ad2492</a>
				</tr></td>
				<tr><td>
					<i>Taxonomy and Real-Time Classification of Artifacts during Biosignal Acquisition: A Starter Study and Dataset of ECG.</i> Liu, H.*, Zhang, S., Gamboa, H., Xue, T., Zhou, C., and Schultz, T. (2024). IEEE Sensors Journal.<br>
					<a href="https://scholar.google.com/scholar?q=Taxonomy+and+Real-Time+Classification+of+Artifacts+during+Biosignal+Acquisition%3A+A+Starter+Study+and+Dataset+of+ECG" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Taxonomy-and-Real-Time-Classification-of-Artifacts-Liu-Zhang/e499518389b2b51b5f4b2a41610f7cf7037818be" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/377731834_Taxonomy_and_Real-Time_Classification_of_Artifacts_during_Biosignal_Acquisition_A_Starter_Study_and_Dataset_of_ECG" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/document/10415350" target="_blank" rel="noopener noreferrer"><img src="images/IEEE.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2024biosignalartifact&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1109/JSEN.2024.3356651" target="_blank" rel="noopener noreferrer">10.1109/JSEN.2024.3356651</a>
				</tr></td>
				<tr><td>
					<i>Understanding Naturalistic Facial Expressions with Deep Learning and Multimodal Large Language Models.</i> Bian, Y., Küster, D., Liu H., and Krumhuber, E. G.* (2024). Sensors, 24(1):126. MDPI.<br>
					<a href="https://scholar.google.com/scholar?q=Understanding+Naturalistic+Facial+Expressions+with+Deep+Learning+and+Multimodal+Large+Language+Models" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Understanding-Naturalistic-Facial-Expressions-with-Bian-K%C3%BCster/6dbb5a3f98625d7d090b37ae36dbf3e64d1f1d0e" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/376840648_Understanding_Naturalistic_Facial_Expressions_with_Deep_Learning_and_Multimodal_Large_Language_Models" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/1424-8220/24/1/126" target="_blank" rel="noopener noreferrer"><img src="images/Sensors.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=bian2024MLLMfacialexpression&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3390/s24010126" target="_blank" rel="noopener noreferrer">10.3390/s24010126</a>
				</tr></td>
				<tr><td>
					<i>Muscle Synergies in Joystick Manipulation.</i> Cai, L., Yan, S., Ouyang C., Zhang, T., Zhu, J., Chen, L., Ma, X.*, and Liu, H.* (2023). Frontiers in Physiology, 14:1282295. Frontiers Media SA.<br>
					<a href="https://scholar.google.com/scholar?q=Muscle+Synergies+in+Joystick+Manipulation" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Muscle-synergies-in-joystick-manipulation-Cai-Yan/b8f4cacd594fed0ec79a4f7b966d22673e864719" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/374675206_Muscle_synergies_in_joystick_manipulation" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.frontiersin.org/articles/10.3389/fphys.2023.1282295/full" target="_blank" rel="noopener noreferrer"><img src="images/Frontiers.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=cai2023joystick&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3389/fphys.2023.1282295" target="_blank" rel="noopener noreferrer">10.3389/fphys.2023.1282295</a>
				</tr></td>
				<tr><td>
					<i>Outlier Detection Using Iterative Adaptive Mini-Minimum Spanning Tree Generation with Applications on Medical Data.</i> Li, J., Li, JW, Wang, C, Verbeek, F. J.*, Schultz T., and Liu H.* (2023). Frontiers in Physiology, 14:1233341. Frontiers Media SA.<br>
					<a href="https://scholar.google.com/scholar?q=Outlier+Detection+Using+Iterative+Adaptive+Mini-Minimum+Spanning+Tree+Generation+with+Applications+on+Medical+Data" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Outlier-detection-using-iterative-adaptive-spanning-Li-Li/fb0fc149b382ef5ce415b44b35ab7352a0eb4b46" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/374675183_Outlier_detection_using_iterative_adaptive_mini-minimum_spanning_tree_generation_with_applications_on_medical_data" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.frontiersin.org/articles/10.3389/fphys.2023.1233341/full" target="_blank" rel="noopener noreferrer"><img src="images/Frontiers.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=li2023outlier_detection&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3389/fphys.2023.1233341" target="_blank" rel="noopener noreferrer">10.3389/fphys.2023.1233341</a>
				</tr></td>
				<tr><td>
					<i>Efficient Wi-Fi-Based Human Activity Recognition Using Adaptive Antenna Elimination.</i> Jannat, M.K.A., Islam, M.S., Yang, S-H*, and Liu, H.* (2023). IEEE Access, 11:105440-105454.<br>
					<a href="https://scholar.google.com/scholar?q=Efficient+Wi-Fi-Based+Human+Activity+Recognition+Using+Adaptive+Antenna+Elimination" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Efficient-Wi-Fi-Based-Human-Activity-Recognition-Jannat-Islam/02ff217d1dd6316596fc1da4b8f6a107ee5b7f06" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/374244149_Efficient_Wi-Fi-Based_Human_Activity_Recognition_Using_Adaptive_Antenna_Elimination" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/document/10265041" target="_blank" rel="noopener noreferrer"><img src="images/IEEE.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=jannat2023wifi_har&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1109/ACCESS.2023.3320069" target="_blank" rel="noopener noreferrer">10.1109/ACCESS.2023.3320069</a>
				</tr></td>
				<tr><td>
					<i>Hybrid Modeling on Reconstitution of Continuous Arterial Blood Pressure Using Finger Photoplethysmography.</i> Shi, W., Zhou, C., Zhang, Y., Li, K., Ren, X., Liu, H.*, and Ye, X.* (2023). Biomedical Signal Processing and Control, 85:104972. Elsevier.<br>
					<a href="https://scholar.google.com/scholar?q=Hybrid+modeling+on+reconstitution+of+continuous+arterial+blood+pressure+using+finger+photoplethysmography" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Hybrid-modeling-on-reconstitution-of-continuous/72ac3930e09b7ec7008ea029cba28ae1ba709e54" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/370529977_Hybrid_Modeling_on_Reconstitution_of_Continuous_Arterial_Blood_Pressure_Using_Finger_Photoplethysmography" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809423004056?via%3Dihub" target="_blank" rel="noopener noreferrer"><img src="images/Elsevier.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=shi2023AbpUsingPpg&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1016/j.bspc.2023.104972" target="_blank" rel="noopener noreferrer">10.1016/j.bspc.2023.104972</a>
				</tr></td>
				<tr><td>
					<i>Feature-Based Information Retrieval of Multimodal Biosignals with a Self-Similarity Matrix: Focus on Automatic Segmentation.</i> Rodrigues, J.*., Liu, H.* (co-first), Folgado, D., Belo, D., Schultz, T., and Gamboa, H.* (2022). Biosensors, 12(12):1182. MDPI.<br>
					<a href="https://scholar.google.com/scholar?q=Feature-Based+Information+Retrieval+of+Multimodal+Biosignals+with+a+Self-Similarity+Matrix%3A+Focus+on+Automatic+Segmentation" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Feature-Based-Information-Retrieval-of-Multimodal-a-Rodrigues-Liu/c824d095fbf7d9afdde8c36909fc70eb569f15c3" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/366410597_Feature-Based_Information_Retrieval_of_Multimodal_Biosignals_with_a_Self-Similarity_Matrix_Focus_on_Automatic_Segmentation" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/2079-6374/12/12/1182" target="_blank" rel="noopener noreferrer"><img src="images/Biosensors.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=rodriguesliu2022ssmnovelty&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3390/bios12121182" target="_blank" rel="noopener noreferrer">10.3390/bios12121182</a>
				</tr></td>
				<tr><td>
					<i>Bell Shape Embodying Zhongyong: The Pitch Histogram of Traditional Chinese Anhemitonic Pentatonic Folk Songs.</i> Liu, H.*, Jiang, K., Gamboa, H., Xue, T., and Schultz, T. (2022). Applied Sciences, 12(16):8343. MDPI.<br>
					<a href="https://scholar.google.com/scholar?q=Bell+Shape+Embodying+Zhongyong%3A+The+Pitch+Histogram+of+Traditional+Chinese+Anhemitonic+Pentatonic+Folk+Songs" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Bell-Shape-Embodying-Zhongyong%3A-The-Pitch-Histogram-Liu-Jiang/db1523092f1e528af3ce41385843e862b74f0ff2" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/362837075_Bell_Shape_Embodying_Zhongyong_The_Pitch_Histogram_of_Traditional_Chinese_Anhemitonic_Pentatonic_Folk_Songs" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.mdpi.com/2076-3417/12/16/8343" target="_blank" rel="noopener noreferrer"><img src="images/Applied_Sciences.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://novaresearch.unl.pt/en/publications/bell-shape-embodying-zhongyong-the-pitch-histogram-of-traditional" target="_blank" rel="noopener noreferrer"><img src="images/Nova.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://run.unl.pt/handle/10362/145647" target="_blank" rel="noopener noreferrer"><img src="images/RUN.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2022bellshape&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3390/app12168343" target="_blank" rel="noopener noreferrer">10.3390/app12168343</a>
				</tr></td>
				<tr><td>
					<i>TSSEARCH: Time Series Subsequence Search Library.</i> Folgado, D. Barandas, M., Antunes, M., Nunes, M. L., Liu, H., Hartmann, Y., Schultz, T., and Gamboa, H. (2022). SoftwareX, 18:101049. Elsevier.<br>
					<a href="https://scholar.google.com/scholar?q=TSSEARCH%3A+Time+Series+Subsequence+Search+Library" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/TSSEARCH%3A-Time-Series-Subsequence-Search-Library-Folgado-Barandas/88ae58d7183b13c72e67f90ee71e20cc87aa61f6" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/359648631_TSSEARCH_Time_Series_Subsequence_Search_Library" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S2352711022000425" target="_blank" rel="noopener noreferrer"><img src="images/Elsevier.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.aicos.fraunhofer.pt/en/publications.html" target="_blank" rel="noopener noreferrer"><img src="images/Aicos.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://novaresearch.unl.pt/en/publications/tssearch-time-series-subsequence-search-library" target="_blank" rel="noopener noreferrer"><img src="images/Nova.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://run.unl.pt/handle/10362/143322" target="_blank" rel="noopener noreferrer"><img src="images/RUN.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=folgado2022tssearch&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/fraunhoferportugal/tssearch" target="_blank" rel="noopener noreferrer"><img src="images/GitHub.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://tssearch.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer"><img src="images/TSSEARCH.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1016/j.softx.2022.101049" target="_blank" rel="noopener noreferrer">10.1016/j.softx.2022.101049</a>
				</td></tr>
				<tr><td>
					<i>CSL-SHARE: A Multimodal Wearable Sensor-Based Human Activity Dataset.</i> Liu, H.*, Hartmann, Y., and Schultz, T. (2021). Frontiers in Computer Science, 3: 759136. Frontiers Media SA.<br>
					<a href="https://scholar.google.com/scholar?q=CSL-SHARE%3A+A+Multimodal+Wearable+Sensor-Based+Human+Activity+Datasets" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/CSL-SHARE%3A-A-Multimodal-Wearable-Sensor-Based-Human-Liu-Hartmann/17dbf3ac9e44c44f45589feffbf447afc0349068" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/355231971_CSL-SHARE_A_Multimodal_Wearable_Sensor-Based_Human_Activity_Dataset" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.frontiersin.org/articles/10.3389/fcomp.2021.759136/full" target="_blank" rel="noopener noreferrer"><img src="images/Frontiers.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2021cslshare&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.uni-bremen.de/en/csl/research/human-activity-recognition" target="_blank" rel="noopener noreferrer"><img src="images/Dataset.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.3389/fcomp.2021.759136" target="_blank" rel="noopener noreferrer">10.3389/fcomp.2021.759136</a>
				</tr></td>
				<tr><td>
					<i>TSFEL: Time Series Feature Extraction Library.</i> Barandas, M., Folgado, D., Fernandes, L., Santos, S., Abreu, M., Bota, P., Liu, H., Schultz, T., and Gamboa, H. (2020). SoftwareX, 11:100456. Elsevier.<br>
					<a href="https://scholar.google.com/scholar?q=TSFEL%3A+Time+series+feature+extraction+library+barandas" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a></b>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/TSFEL%3A-Time-Series-Feature-Extraction-Library-Barandas-Folgado/30d86ed68c163455b8f3ef10a5bf4c92ee8707bc" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/340085788_TSFEL_Time_Series_Feature_Extraction_Library" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S2352711020300017" target="_blank" rel="noopener noreferrer"><img src="images/Elsevier.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://novaresearch.unl.pt/en/publications/tsfel-time-series-feature-extraction-library" target="_blank" rel="noopener noreferrer"><img src="images/Nova.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://run.unl.pt/handle/10362/117283" target="_blank" rel="noopener noreferrer"><img src="images/RUN.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=barandas2020tsfel&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/fraunhoferportugal/tsfel" target="_blank" rel="noopener noreferrer"><img src="images/GitHub.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://tsfel.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer"><img src="images/TSFEL.png" height="15" class="pop15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1016/j.softx.2020.100456" target="_blank" rel="noopener noreferrer">10.1016/j.softx.2020.100456</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<b>(Top-cited on <a href="https://www.journals.elsevier.com/softwarex" target="_blank" rel="noopener noreferrer">Software X</a>)
				</tr></td>
			
				<tr><td>
					<img src="images/Conference.png" height="25">
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Comfort Assessment Method of EEG-Based Exoskeleton Walking-Assistive Device.</i> Zhou, C., Wang, H., Li, K., Liu, H., and Ye, X. (2024).  In Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC). INSTICC, SciTePress.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Really Can't Hold on Anymore? Physiological Indicators Versus Self-Reported Motivation Drop During Jogging.</i> Zhang, S., Kolensnikov, S., Rennspieß, T., Porzel, R., Schultz, T., and Liu, H. (2024).  In Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC). INSTICC, SciTePress.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Associating Endpoint Accuracy and Similarity of Muscle Synergies.</i> Cai, L., Yan, S., Ouyang, C., Zhang, T., Zhu, J., Chen, L., and Liu, H. (2024).  In Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC). INSTICC, SciTePress.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Integrated Driver Pose Estimation for Autonomous Driving.</i> Cao, X., Hu, W., and Liu, H. (2024).  In Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC). INSTICC, SciTePress.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<img src="images/Forthcoming.png" height="20" class = "pop1">
					<i>Can Electromyography Alone Reveal Facial Action Units? A Pilot EMG-Based Action Unit Recognition Study with Real-Time Validation.</i> Veldanda, A., Liu, H., Koschke, R., Schultz, T., and Küster, D. (2024).  In Proceedings of the 17th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 1: BIODEVICES, pages ?–?. INSTICC, SciTePress.<br>
					<!--
					<a href="" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/" target="_blank" rel="noopener noreferrer"></a>
					-->
				</tr></td>
				<tr><td>
					<i>On a Real Real-Time Wearable Human Activity Recognition System.</i> Liu, H., Xue, T., and Schultz, T. (2023). In Proceedings of the 16th International Joint Conference on Biomedical Engineering Systems and Technologies - WHC, pages 711-720. INSTICC, SciTePress.<br> 
					<a href="https://scholar.google.com/scholar?q=on+a+real+real-time+wearable+human+activity+recognition+system" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/On-a-Real-Real-Time-Wearable-Human-Activity-System-Liu-Xue/1c0648a61e011468faf3289fcee39ec66b2a4d43" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/369015090_On_a_Real_Real-Time_Wearable_Human_Activity_Recognition_System" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0011927700003414" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2023realtime&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0011927700003414" target="_blank" rel="noopener noreferrer">10.5220/0011927700003414</a>
				</tr></td>
				<tr><td>
					<i>Merged Pitch Histogram and Pitch-Duration Histogram.</i> Liu, H., Xue, T., and Schultz, T. (2022). In Proceedings of the 19th International Conference on Signal Processing and Multimedia Applications, pages 32-39. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=Merged+Pitch+Histograms+and+Pitch-Duration+Histograms" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Merged-Pitch-Histograms-and-Pitch-duration-Liu-Xue/1e4d841d8e492c2bad6a28b9f7275f5c1f64dd12" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/362055213_Merged_Pitch_Histograms_and_Pitch-duration_Histograms" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0011310300003289" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2022pitchhistogram&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0011310300003289" target="_blank" rel="noopener noreferrer">10.5220/0011310300003289</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<b>(Best Paper Award Finalist)</b>
				</tr></td>
				<tr><td>
					<i>Interactive and Interpretable Online Human Activity Recognition.</i> Hartmann, Y., Liu, H., and Schultz, T. (2022). In PERCOM 2022 - 20th IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events, pages 109–111. IEEE.<br>
					<a href="https://scholar.google.com/scholar?q=Interactive+and+Interpretable+Online+Human+Activity+Recognition" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Interactive-and-Interpretable-Online-Human-Activity-Hartmann-Liu/06f9c40b080318751f1667e9ac569d2da4abfd44" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/359692528_Interactive_and_Interpretable_Online_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/document/9767207" target="_blank" rel="noopener noreferrer"><img src="images/IEEE.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=hartmann2022demo&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1109/PerComWorkshops53856.2022.9767207" target="_blank" rel="noopener noreferrer">10.1109/PerComWorkshops53856.2022.9767207</a>
				</td></tr>
				<tr><td>
					<i>A Practical Wearable Sensor-Based Human Activity Recognition Research Pipeline.</i> Liu, H., Hartmann, Y., and Schultz, T. (2022).  In Proceedings of the 15th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 5: HEALTHINF, pages 851-860. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=A+Practical+Wearable+Sensor-Based+Human+Activity+Recognition+Research+Pipeline" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/A-Practical-Wearable-Sensor-based-Human-Activity-Liu-Hartmann/2e8a7e003683f7f6dca0ba3995c4c971cdfd9de9" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/358567885_A_Practical_Wearable_Sensor-Based_Human_Activity_Recognition_Research_Pipeline" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0010937000003123" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2022pipeline&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0010937000003123" target="_blank" rel="noopener noreferrer">10.5220/0010937000003123</a>
				</td></tr>
				<tr><td>
					<i>How Long Are Various Types of Daily Activities? Statistical Analysis of a Multimodal Wearable Sensor-Based Human Activity Dataset.</i> Liu, H., and Schultz, T. (2022). In Proceedings of the 15th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 5: HEALTHINF, pages 684-692. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=How+long+are+various+types+of+daily+activities%3F+statistical+analysis+of+a+multimodal+wearable+sensor-based+human+activity+dataset" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/How-Long-Are-Various-Types-of-Daily-Activities-of-a-Liu-Schultz/b1be768408ec57e85573824e9acee3b6db7376ac" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/358568068_How_Long_Are_Various_Types_of_Daily_Activities_Statistical_Analysis_of_a_Multimodal_Wearable_Sensor-Based_Human_Activity_Dataset" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0010896400003123" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2022activityduration&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0010896400003123" target="_blank" rel="noopener noreferrer">10.5220/0010896400003123</a>
				</td></tr>
				<tr><td>
					<i>Interpretable High-Level Features for Human Activity Recognition.</i> Hartmann, Y., Liu, H., Lahrberg, S., and Schultz, T. (2022). In Proceedings of the 15th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 4: BIOSIGNALS, pages 40-49. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=Interpretable+high-level+features+for+human+activity+recognition" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Interpretable-High-level-Features-for-Human-Hartmann-Liu/df0bab3545d7509081bf2e5b40bca2e5333e25e9" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/358568253_Interpretable_High-Level_Features_for_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0010840500003123" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=hartmann2022highlevelfeature&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0010840500003123" target="_blank" rel="noopener noreferrer">10.5220/0010840500003123</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<b>(Best Student Paper Award Finalist)</b>
				</td></tr>
				<tr><td>
					<i>Motion Units: Generalized Sequence Modeling of Human Activities for Sensor-Based Activity Recognition.</i> Liu, H., Hartmann, Y., and Schultz, T. (2021). In EUSIPCO 2021 - 29th European Signal Processing Conference. IEEE.<br>
					<a href="https://scholar.google.com/scholar?q=Motion+Units%3A+Generalized+Sequence+Modeling+of+Human+Activities+for+Sensor-Based+Activity+Recognition" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Motion-Units%3A-Generalized-Sequence-Modeling-of-for-Liu-Hartmann/7299d035bdb6e37058dd28f123e190fd4915a5e4" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/356883313_Motion_Units_Generalized_Sequence_Modeling_of_Human_Activities_for_Sensor-Based_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/document/9616298" target="_blank" rel="noopener noreferrer"><img src="images/IEEE.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2021motionunits&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.23919/EUSIPCO54536.2021.9616298" target="_blank" rel="noopener noreferrer">10.23919/EUSIPCO54536.2021.9616298</a>
				</tr></td>
				<tr><td>
					<i>Feature Space Reduction for Human Activity Recognition Based on Multi-Channel Biosignals.</i> Hartmann, Y., Liu, H., and Schultz, T. (2021). In Proceedings of the 14th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 4: BIOSIGNALS, pages 215-222. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=Feature+Space+Reduction+for+Human+Activity+Recognition+based+on+Multi-channel+Biosignals." target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Feature-Space-Reduction-for-Human-Activity-based-on-Hartmann-Liu/98ebf6536aaaef7689f850664903c8c877843cd7" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/349384072_Feature_Space_Reduction_for_Human_Activity_Recognition_based_on_Multi-channel_Biosignals" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0010260802150222" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=hartmann2021featurespace&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0010260802150222" target="_blank" rel="noopener noreferrer">10.5220/0010260802150222</a>
				</tr></td>
				<tr><td>
					<i>Feature Space Reduction for Multimodal Human Activity Recognition.</i> Hartmann, Y., Liu, H., and Schultz, T. (2020). In Proceedings of the 13th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 4: BIOSIGNALS, pages 135–140. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=Feature+Space+Reduction+for+Multimodal+Human+Activity+Recognition." target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Feature-Space-Reduction-for-Multimodal-Human-Hartmann-Liu/34bce7b4cbd0600001597c1d5c683a4090df7187" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/339903026_Feature_Space_Reduction_for_Multimodal_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0008851401350140" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=hartmann2020featurespace&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0008851401350140" target="_blank" rel="noopener noreferrer">10.5220/0008851401350140</a>
				</tr></td>
				<tr><td>
					<i>A Wearable Real-Time Human Activity Recognition System using Biosensors Integrated into a Knee Bandage.</i> Liu, H., and Schultz, T. (2019). In Proceedings of the 12th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 1: BIODEVICES, pages 47–55. INSTICC, SciTePress.<br>
					<a href="https://scholar.google.com/scholar?q=A+Wearable+Real-time+Human+Activity+Recognition+System+using+Biosensors+Integrated+into+a+Knee+Bandage." target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/A-Wearable-Real-time-Human-Activity-Recognition-a-Liu-Schultz/9d550549149560b091f92e0bcc294d063ee8856a" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/331779900_A_Wearable_Real-time_Human_Activity_Recognition_System_using_Biosensors_Integrated_into_a_Knee_Bandage" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0007398800470055" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2019realtimehar&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0007398800470055" target="_blank" rel="noopener noreferrer">10.5220/0007398800470055</a>
					&nbsp;&nbsp;&nbsp;&nbsp;<b>(<a href="https://biostec.scitevents.org/PreviousAwards.aspx#2019" target="_blank" rel="noopener noreferrer">Best Paper Award</a>, Student Author)</b>
				</tr></td>
				<tr><td>
					<i>ASK: A Framework for Data Acquisition and Activity Recognition.</i> Liu, H., and Schultz, T. (2018). In Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies - Volume 3: BIOSIGNALS, pages 262–268. INSTICC, SciTePress.
					<br>
					<a href="https://scholar.google.com/scholar?q=ASK%3A+A+Framework+for+Data+Acquisition+and+Activity+Recognition." target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/ASK%3A-A-Framework-for-Data-Acquisition-and-Activity-Liu-Schultz/0321ad383bc44905ba73967a87570363cc57cd12" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/322873353_ASK_A_Framework_for_Data_Acquisition_and_Activity_Recognition" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://doi.org/10.5220/0006732902620268" target="_blank" rel="noopener noreferrer"><img src="images/SciTePress.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.csl.uni-bremen.de/cms/publications/bibtexbrowser.php?key=liu2018harframework&bib=csl_all_publications.bib" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.5220/0006732902620268" target="_blank" rel="noopener noreferrer">10.5220/0006732902620268</a>
				</tr></td>
				<tr><td>
					<i>Capacity of Cooperative Ad Hoc Networks with Heterogeneous Traffic Patterns.</i> Liu, H., and Wang, X. (2011). In ICC 2011 - IEEE International Conference on Communications, pages 1–5. IEEE.<br>
					<a href="https://scholar.google.com/scholar?q=Capacity+of+Cooperative+Ad+Hoc+Networks+with+Heterogeneous+Traffic+Patterns" target="_blank" rel="noopener noreferrer"><img src="images/GoogleScholar.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.semanticscholar.org/paper/Capacity-of-Cooperative-Ad-Hoc-Networks-with-Liu-Wang/b4abbc50f034d33c326ee11f98d1d7e9e189d8e2" target="_blank" rel="noopener noreferrer"><img src="images/Semantic.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.researchgate.net/publication/224249853_Capacity_of_Cooperative_Ad_Hoc_Networks_with_Heterogeneous_Traffic_Patterns" target="_blank" rel="noopener noreferrer"><img src="images/ResearchGate.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ieeexplore.ieee.org/abstract/document/5963075" target="_blank" rel="noopener noreferrer"><img src="images/IEEE.png" height="15"></a>
					&nbsp;&nbsp;&nbsp;&nbsp;<img src="images/doi.png" height="15"><a href="https://doi.org/10.1109/icc.2011.5963075" target="_blank" rel="noopener noreferrer">10.1109/icc.2011.5963075</a>
				</tr></td>
			</table></td></tr>

			<tr><td></td></tr><tr><td></td></tr>

			<tr><td><h1 align="left"><span style="text-decoration: overline">学术贡献</span></h1></td><tr>
			<tr><td><table align="left" cellpadding="15">
				<tr>
					<td align="center">编委</td>
					<td>
						<img src="images/IOP.png" height="20" class="pop1"><br>
						&#9679; <a href="https://publishingsupport.iopscience.iop.org/journals/engineering-research-express/editorial-board/" target="_blank" rel="noopener noreferrer">Engineering Research Express</a><br>
						<img src="images/Frontiers.png" height="25" class="pop1"><br>
						&#9679; <a href="https://loop.frontiersin.org/people/1257413/overview" target="_blank" rel="noopener noreferrer">Frontiers in Big Data</a><br>
						&#9679; <a href="https://loop.frontiersin.org/people/1257413/overview" target="_blank" rel="noopener noreferrer">Frontiers in Artificial Intelligence</a>
					</td>
				</tr>
				<tr>
					<td align="center">编辑</td>
					<td>
						<img src="images/Frontiers.png" height="25" class="pop1"><br>
						&#9679; Frontiers in Behavioral Neuroscience<br>
					</td>
				</tr>
				<tr>
					<td align="center">特邀编委</td>
					<td>
						<img src="images/MDPI.png" height="25"><br>
						&#9679; <img src="images/Sensors.png" height="15">	Sensors 专刊 <i>Sensors for Human Activity Recognition</i>: 
						<a href="https://www.mdpi.com/journal/sensors/special_issues/Sensors_Human_Activity_Recognition" target="_blank" rel="noopener noreferrer">卷I</a>
						<a href="https://www.mdpi.com/journal/sensors/special_issues/671TM05M9J" target="_blank" rel="noopener noreferrer">卷II</a>
					</td>
				</tr>
				<tr>
					<td align="center">学术会议 Program Chair</td>
					<td>
						<a href="https://biostec.scitevents.org/?y=2024" target="_blank" rel="noopener noreferrer"><img src="images/BIOSTEC2024.png" height="23" class="pop1"></a> &nbsp
						<a href="https://biosignals.scitevents.org/?y=2024" target="_blank" rel="noopener noreferrer"><img src="images/BIOSIGNALS2024.png" height="23" class="pop1"></a><br>
						&#9679; BIOSIGNALS2024 - 17<sup>th</sup> International Conference on Bio-Inspired Systems and Signal Processing (in BIOSTEC 2024), Rome, Itaty
					</td>
				</tr>
				<tr>
					<td align="center">学术会议 Area Chair</td>
					<td>
						<a href="https://e-nns.org/icann2024/" target="_blank" rel="noopener noreferrer"><img src="images/ICANN2024.png" height="23" class="pop1"></a><br>
						&#9679; BIOSIGNALS2024 - 33<sup>rd</sup> International Conference on Artificial Neural Networks, Lugano, Switzerland
					</td>
				</tr>
				<tr>
					<td align="center">学术会议 Session Chair</td>
					<td>
						<a href="https://healthinf.scitevents.org/?y=2022" target="_blank" rel="noopener noreferrer"><img src="images/HEALTHINF22.png" height="23" class="pop1"></a><br>
						&#9679; 15<sup>th</sup> International Conference on Health Informatics (in BIOSTEC 2022), Vienna, Austria<br><br>
						<a href="https://sigmap.scitevents.org/?y=2022" target="_blank" rel="noopener noreferrer"><img src="images/SIGMAP22.png" height="23" class="pop1"></a><br>
						&#9679; 19<sup>th</sup> International Conference on Signal Processing and Multimedia Applications, Lisbon, Portugal<br><br>
						<a href="https://biostec.scitevents.org//?y=2023" target="_blank" rel="noopener noreferrer"><img src="images/BIOSTEC2023.png" height="23" class="pop1"></a><br>
						&#9679; 16<sup>th</sup> International Joint Conference on Biomedical Engineering Systems and Technologies, Lisbon, Portugal
					</td>
				</tr>
				<tr>
					<td align="center"><a href="reviewer.html" target="_blank" rel="noopener noreferrer">审稿人</a></td>
					<td>
						&#9679; 38本国际期刊，包括Nat. Commun.、Biomed. Signal Process. Control、Remote Sens.、Front. Physiol.、Front Bioeng. Biotechnol.、Physiol. Meas.、Phys. Scr.、 ISPRS Int. J. Geo-Inf.、Biomimetics、Biosensors<br>
						&#9679; 多个国际会议, 包括IEEE BSN, BHI; ACM ICMI, ISWC, AUTOMOTIVEUI; ITP<br>
						&#9679; <a href="images/IOP_Certificate.png" target="_blank" rel="noopener noreferrer">IOP Trusted Reviewer</a> 表彰“极其高水平的同行评审胜任力”（<i>an exceptionally high level of peer review competency</i>）
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.uni-bremen.de/en/csl/projects/past-projects/arthrokinemat" target="_blank" rel="noopener noreferrer"><img src="images/Arthrokinemat.png" height="60" class="pop5"></a><br>Arthrokinemat (2016 — 2019)</td>
					<td>
						&#9679; 主研德国联邦经济事务与气侯行动部（BMWi）Arthrokinemat项目<br>
						&#9679; 康复工程中的集成传感器智能膝盖绷带<br>
						&#9679; 已经成功结题
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.uni-bremen.de/en/csl/projects/current-projects/nf-bwb-promoting-young-talents-supported-by-bremen-securities-exchange-foundation" target="_blank" rel="noopener noreferrer"><img src="images/BWB.png" height="60" class="pop5"></a><br>NF-BWB (2023 — 2025)</td>
					<td>
						&#9679; 主研德国不来梅证券基金会（BWB）资助的NF-BWB"青年英才培养"项目  <a href="images/BBDCB23.png" target="_blank" rel="noopener noreferrer"><img src="images/BBDCB23.png" width="20" class="pop40"></a><br>
						&#9679; 在多所高校普及人工智能和大数据，并举办竞赛
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.uni-bremen.de/en/csl/projects/current-projects/intel4coro" target="_blank" rel="noopener noreferrer"><img src="images/IntEL4CoRo.png" height="60" class="pop5"></a><br>IntEL4CoRo (2021 — 2025)</td>
					<td>
						&#9679; 主研德国联邦教育及研究部（BMBF）IntEL4CoRo项目<br>
						&#9679; 智能机器人设计仿真教学平台
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.uni-bremen.de/en/csl/projects/current-projects/etap" target="_blank" rel="noopener noreferrer"><img src="images/ETAP.png" height="60" class="pop5"></a><br>ETAP (2022 — 2025)</td>
					<td>
						&#9679; 参与起草德国联邦卫生部（BMG）ETAP项目<br>
						&#9679; 基于人工智能运动监测的长期护理中半自动化护理优化
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://yerun.eu/" target="_blank" rel="noopener noreferrer"><img src="images/YERUN.png" height="40"></a><br>欧洲青年研究型大学网络</td>
					<td>&#9679; YERUN学者：<a href="https://yerun.eu/2022/09/yerun-research-mobility-awards-2022-results-out-now-check-out-who-has-been-awarded/" target="_blank" rel="noopener noreferrer">科研流动奖金</a></td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.unl.pt" target="_blank" rel="noopener noreferrer"><img src="images/Nova.png" height="40"></a><br>葡萄牙新里斯本大学</td>
					<td>&#9679; <a href="https://www.uni-bremen.de/lehre-studium/lehren-und-lernen-international/erasmus-dozentenmobilitaet" target="_blank" rel="noopener noreferrer"><img src="images/Erasmus.svg" width="10" class="pop15"></a> 欧盟伊拉斯谟海外教学奖学金</td>
				</tr>
				<tr>
					<td align="center"><a href="https://biosignalsplux.com/learn/notebooks/Categories/Train_And_Classify/emg_fist_classifier_rev.php" target="_blank" rel="noopener noreferrer"><img src="images/biosignalsnotebooks.png" height="50"></a><br>Biosignals Notebooks</td>
					<td>&#9679; 传感器人工智能公益在线教程和代码开源</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.cdhawer.com/" target="_blank" rel="noopener noreferrer"><img src="images/CAMT.png" height="35"></a><br>同济大学中德工程学院<br>德国杜塞尔多夫 2018</td>
					<td>&#9679; 学术讲座：<i><a href="https://www.cdhawer.com/meeting-news-2018/" target="_blank" rel="noopener noreferrer">学术与艺术</a></i> <img src="images/CAMTTalk.jpg" width="15" class="pop40"></td>
				</tr>
				<tr>
					<td align="center"><a href="https://biostec.scitevents.org/?y=2019" target="_blank" rel="noopener noreferrer"><img src="images/BIOSTEC2019.png" height="23" class="pop1"></a><br>第12届国际生物医学工<br>程系统和技术联合会议<br>捷克布拉格 2019</td>
					<td>&#9679; 学术讲座：<i><a href="https://biostec.scitevents.org/Tutorials.aspx?y=2019#3" target="_blank" rel="noopener noreferrer">From Offline towards Real-Time</a></i></td>
				</tr>
				<tr>
					<td align="center"><a href="https://kd2school.info/" target="_blank" rel="noopener noreferrer"><img src="images/KD2School.png" height="60"></a><br>卡尔斯鲁厄理工学院（KIT）<br>	适应性系统年度座谈会<br>德国卡尔斯鲁厄 2022</td>
					<td>&#9679; 特邀技术展示 <img src="images/KD2School_Workshop.png" width="22" class="pop40"></td>
				</tr>
				<tr>
					<td align="center"><a href="https://bbdc.csl.uni-bremen.de/index.php/2019h/25-bbdc-2019" target="_blank" rel="noopener noreferrer"><img src="images/BBDC2019.png" height="60"></a><br>第4届北德大数据竞赛<br>BBDC 2019</td>
					<td>
						&#9679; （独立承担）大数据采集、处理和提供工作<br>
						&#9679; 北德数十所高校的60多支队伍参加最后的角逐
					</td>
				</tr>
			</table></td></tr>

			<tr><td></td></tr><tr><td></td></tr>

			<tr><td><h1 align="left"><span style="text-decoration: overline">产研活动</span></h1></td><tr>
			<tr><td><table align="left" cellpadding="15">
				<tr>
					<td align="center"><a href="https://bremen.ai/" target="_blank" rel="noopener noreferrer"><img src="images/BremenAI.png" height="70" class="pop1"></a><br>不来梅人工智能展览会<br>德国不来梅 2019</td>
					<td>
						&#9679; 技术演示：实时人体动作识别系统<br>
						&#9679; 互动演示：MR（混合现实）康复辅助游戏平台<br>
						&#9679; 举办地：<a href="https://www.mevis.fraunhofer.de/de.html" target="_blank" rel="noopener noreferrer"><img src="images/MEVIS.png" width="40" class="pop5"></a> 弗劳恩霍夫协会数字医学研究所
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://frauenseiten.bremen.de/termine/mindday-kognitionswissenschaft-zum-anfassen/" target="_blank" rel="noopener noreferrer"><img src="images/MindDay.png" height="30"></a><br>“智慧头脑日”展览研讨会<br>德国不来梅 2021</td>
					<td>
						&#9679; 技术演示：人工智能膝盖绷带 <img src="images/MindDay21.jpg" width="20" class="pop40"><br>
						&#9679; 举办地：<a href="https://www.uebersee-museum.de/" target="_blank" rel="noopener noreferrer"><img src="images/Museum.png" width="12" class="pop5"></a> 不来梅海外博物馆</td>
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.pluxbiosignals.com/" target="_blank" rel="noopener noreferrer"><img src="images/PLUX.png" height="60" class="pop1"></a><br>葡萄牙 PLUX<br>无线生物信号传感器公司</td>
					<td>&#9679; <a href="https://qrco.de/bdHmtW" target="_blank" rel="noopener noreferrer">科技顾问</a><td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.bridge-online.de/campusideen" target="_blank" rel="noopener noreferrer"><img src="images/CAMPUSiDEEN22.jpg" height="50" class="pop5"></a><br>CAMPUSiDEEN 2022<br>商业创意大赛<br></td>
					<td>&#9679; 公共选择奖 <img src="images/CAMPUSiDEEN.png" width="17" class="pop40"><td>
				</tr>
			</table></td></tr>
			<tr><td></td></tr><tr><td></td></tr>

			<tr><td><h1 align="left"><span style="text-decoration: overline">专业履历</span></h1></td></tr>
			<tr><td><table align="left" cellpadding="15">
				<tr>
					<td align="center">
						<a href="http://www.shixi.edu.sh.cn/" target="_blank" rel="noopener noreferrer"><img src="images/Shixi.png" width="60"></a><br>
						2001 — 2004<br>
						上海市市西中学
					</td>
					<td>
						&#9679; 高中，期间获得：<br>
						&#9679; 全国青少年信息学奥林匹克联赛提高组一等奖<br>
						&nbsp;&nbsp;（证书编号：<a href="https://www.chsi.com.cn/mdgs2004/bss/info_sj/200504/20050401/5922.html" target="_blank" rel="noopener noreferrer">I030473</a>）<br>
						&#9679; 上海市CASIO杯程序设计竞赛高中组一等奖
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.sjtu.edu.cn/" target="_blank" rel="noopener noreferrer"><img src="images/SJTU.svg" width="60"></a><br>
						2004 — 2007<br>
						上海交通大学<br>
						电子信息与电气工程学院<br>
						通信工程专业
					</td>
					<td>
						<!--
						&nbsp;&nbsp; <img src="images/BachelorDegree.png" height="40" class="pop15">&nbsp;
						<img src="images/BachelorDiploma.png" height="40" class="pop15"><br>
						-->
						&#9679; 本科学位<br>
						&#9679; 上海交通大学奖学金（三年）
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.tu.berlin/" target="_blank" rel="noopener noreferrer"><img src="images/TUB.png" width="60"></a><br>
						2007 — 2009<br>
						柏林工业大学<br>
						电子学与信息学系（四系）<br>
						<a href="https://www.nue.tu-berlin.de/menue/home/" target="_blank" rel="noopener noreferrer">信号传输专业</a><br>
						<a href="https://www.tu.berlin/qu/" target="_blank" rel="noopener noreferrer">通信质量和适用性专业</a><br>
						<a href="https://www.cv.tu-berlin.de/menue/computer_vision_remote_sensing/" target="_blank" rel="noopener noreferrer">机器视觉专业</a>
					</td>
					<td>
						&nbsp;&nbsp;
						<!--
						<img src="images/Diplom.png" height="40" class="pop15">
						-->
						<img src="images/DiplomNoten.png" height="40" class="pop20"><br>
						&#9679; 第一硕士学位：Diplom-Ingenieur<br>
						&#9679; 课程平均分：1.0<br>
						&#9679; 担任研究助理，于<br>&nbsp;&nbsp;&nbsp;<a href="https://www.hhi.fraunhofer.de/index.html" target="_blank" rel="noopener noreferrer"><img src="images/HHI.png" width="50" class="pop5"></a> 弗劳恩霍夫协会赫兹通讯研究所
					</td>
				<tr>
				<tr>
					<td align="center">
						<a href="https://www.sjtu.edu.cn/" target="_blank" rel="noopener noreferrer"><img src="images/SJTU.svg" width="60"></a><br>
						2009 — 2011<br>
						上海交通大学<br>
						电子信息与电气工程学院<br>
						通信与信息系统专业
					</td>
					<td>
						&nbsp;&nbsp; <img src="images/MasterGPA.png" height="50" class="pop15">&nbsp;
						<img src="images/MasterRanking.png" height="50" class="pop15"><br>
						&#9679; 第二硕士学位：Master of Science<br>
						&#9679; 学积分/积点/GPA：3.16/3.3<br>
						&#9679; GPA排名：1/106<br>
						&#9679; 国家优秀研究生一等奖学金
					</td>
				</tr>
				<tr>
					<td align="center"><a href="https://www.tu.berlin/" target="_blank" rel="noopener noreferrer"><img src="images/TUB.png" width="60"></a><br>2012 — 2013<br>柏林工业大学</td>
					<td>&#9679; 科研助理<br>&#9679; 柏林工业大学校长奖学金</td>
				</tr>
				<tr>
					<td align="center"><img src="images/FP.png" width="60"><br>2014 — 2016<br>企业界工作</td>
					<td>&#9679; 软件工程师<br>&#9679; 负责集成开发项目</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2016 — 2021<br>
						不来梅大学<br>
						数学和信息学系（三系）<br>
						认知系统实验室（CSL）
					</td>
					<td>
						&#9679; 科研项目和教学工作，2021年获工程学博士学位 <a href="videos/2021_Verteidigung.mp4" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="12"></a><br>
						&#9679; 负责德国联邦经济事务和能源部 <a href="https://www.uni-bremen.de/csl/projekte/abgelaufene-projekte/arthrokinemat" target="_blank" rel="noopener noreferrer"><i>Arthrokinemat</i></a> 项目 <img src="images/Arthrokinemat.png" width="20" class="pop25"><br>
						&#9679; 研发首款实时识别人体动作、辅助康复的智能膝盖绷带<br>
						&#9679; <a href="https://biostec.scitevents.org/PreviousAwards.aspx#2019" target="_blank" rel="noopener noreferrer"><img src="images/BIOSTEC2019.png" width="80"> </a><a href="https://biostec.scitevents.org/PreviousAwards.aspx#2019" target="_blank" rel="noopener noreferrer">最佳论文奖</a>（学生作者）<img src="images/BestPaperAward.png" height="20" class="pop25"><br>
						&#9679; 建立广泛和密切的合作关系：<br>
						&nbsp;&nbsp; <a href="https://www.sport.kit.edu/Institut.php" target="_blank" rel="noopener noreferrer"><img src="images/KIT.png" width="20" class="pop5"></a> 卡尔斯鲁厄理工学院<br>
						&nbsp;&nbsp; <a href="https://www.bauerfeind.de/" target="_blank" rel="noopener noreferrer"><img src="images/Bauerfeind.png" width="60"  class="pop5"></a> <a href="https://www.bauerfeind.com.cn/" target="_blank" rel="noopener noreferrer">保尔范</a>运动护具公司等<br>
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2021年以来<br>
						不来梅大学
					</td>
					<td>
						&#9679; 博士后研究员<br><br>
						&nbsp;&nbsp; <a href="https://www.uni-bremen.de/en/csl/institute/team/staff/dr-hui-liu" target="_blank" rel="noopener noreferrer"><img src="images/EN.svg" height="12" class="pop2"></a>
						&nbsp;&nbsp; <a href="https://www.uni-bremen.de/csl/institut/team/mitarbeiter/dr-hui-liu" target="_blank" rel="noopener noreferrer"><img src="images/DE.svg" height="12" class="pop2"></a>
						&nbsp;&nbsp;&nbsp; <a href="https://www.uni-bremen.de/csl/institut/team/mitarbeiter" target="_blank" rel="noopener noreferrer"><img src="images/CSLTeam.png" height="14" class="pop40"></a>
					</td>
				</tr>
			</table></td></tr>

			<tr><td></td></tr><tr><td></td></tr>

			<tr><td><h1 align="left"><span style="text-decoration: overline">教学工作</span></h1></td></tr>
			<tr><td><table align="left" cellpadding="15">
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2022年以来<br>
						<a href="https://www.uni-bremen.de/en/csl/teaching/winter-semester-2022-23/hot-topics-in-sensors-and-human-activity-research-03-ims-tshar" target="_blank" rel="noopener noreferrer"><b>传感器和人体动作研究</b></a>（英/德）
					</td>
					<td>
						&#9679; 课程负责人<br>
						&#9679; 研讨会和学习指导
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2022年以来<br>
						<a href="https://www.uni-bremen.de/csl/lehre/wintersemester-2022-23/ausgewaehlte-probleme-kognitiver-systeme" target="_blank" rel="noopener noreferrer"><b>认知系统</b></a>（德）
					</td>
					<td>
						&#9679; 合作教学<br>
						&#9679; 研讨会和学习指导
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2017年以来<br>
						<a href="https://www.uni-bremen.de/csl/lehre/sommersemester-2021/biosignale-und-benutzerschnittstellen" target="_blank" rel="noopener noreferrer"><b>生物医学信号和用户界面</b></a>（德）
					</td>
					<td>
						&#9679; 课程组织和电子教学平台、部分授课任务<br>
						&#9679; 习题课、线下和线上答疑<br>
						&#9679; 试卷命题人、口试委员<br>
						&#9679; 虚拟教学和线上同步指导负责人（疫情期间）
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2020 — 2021<br>
						<a href="https://www.uni-bremen.de/csl/lehre/sommersemester-2021/grundlagen-des-maschinellen-lernens" target="_blank" rel="noopener noreferrer"><b>机器学习导论</b></a>（英）
					</td>
					<td>
						&#9679; 合作教学<br>
						&#9679; 网络教学视频录制和制作（疫情期间）<br>
						&#9679; 负责聚类分析和聚类算法
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2020 — 2021<br>
						<a href="https://www.informatik.uni-bremen.de/projekttag/2021/projekte/robarinth/" target="_blank" rel="noopener noreferrer"><b>科学工程实践</b></a>: <a href="https://www.szi.uni-bremen.de/wp-content/uploads/2020/01/roboarinth.pdf" target="_blank" rel="noopener noreferrer"><i>RobARinth</i></a>（德）
					</td>
					<td>
						&#9679; 引导项目实践<br>
						&#9679; 提供生物信号传感器技术指导
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.uni-bremen.de/" target="_blank" rel="noopener noreferrer"><img src="images/UB.png" height="40"></a>&nbsp;&nbsp;
						<a href="https://www.uni-bremen.de/csl" target="_blank" rel="noopener noreferrer"><img src="images/CSL.svg" height="40"></a><br>
						2016 — 2018<br>
						<a href="http://www.informatik.uni-bremen.de/st/Lehre/swpII_1718/index.html" target="_blank" rel="noopener noreferrer"><b>软件工程II</b></a>（德）
					</td>
					<td>
						&#9679; 软件设计和软件工程教学<br>
						&#9679; 指导小组实践<br>
						&#9679; 组织参与客户会议和客户需求分析<br>
						&#9679; 指导程序设计和代码优化
					</td>
				</tr>
				<tr>
					<td align="center">
						<a href="https://www.sjtu.edu.cn/" target="_blank" rel="noopener noreferrer"><img src="images/SJTU.svg" width="60"></a><br>
						2010 — 2011<br>
						<a href="https://www.icourses.cn/sCourse/course_2929.html" target="_blank" rel="noopener noreferrer"><b>基本电路理论</b></a>（英）
					</td>
					<td>&#9679; 助教</td>
				</tr>
			</table></td></tr>
			
			<tr><td><table align="left" cellpadding="15">
				<tr><td><b>指导完成的有代表性的优秀本科、硕士毕业论文</b>：</td></tr>
				<tr><td><iframe align="center" width="400%" height="280" src="supervision.html" frameborder="0" scrolling="yes"></iframe></td></tr>
			</table></td></tr>

			<tr><td><table align="left" cellpadding="15">
				<tr><td><a href="studentscn.html" target="_blank" rel="noopener noreferrer"><b>指导的科研助理以及毕设学生列表</b></a></td></tr>
				<tr><td>
					<a href="images/students/Students_2023.jpg" target="_blank" rel="noopener noreferrer"><img src="images/students/Students_2023.jpg" height="315" class="pop1"></a><br>
					指导的科研小组部分成员合影（2023）
				</td></tr>
			</table></td></tr>

			
			<tr><td></td></tr><tr><td></td></tr>
		
			<tr><td><h3 align="left"><font face="sans" size="5">
				&nbsp;&nbsp;<a href="indexcn.html">首 页</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a>学 术</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="artcn.html">艺 术</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="academictreecn.html">学术族谱</a>&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="arttreecn.html">艺术族谱</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="research.html"><img src="images/EN.svg" height="15"></a>
			</font></h3></td></tr>

			<tr><td></td></tr>
		</table><br>
	</body>
</html>